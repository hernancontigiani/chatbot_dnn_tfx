{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jmSf70qa41Ut"
      },
      "source": [
        "# NLP - Bot basado en reglas con Tensorflow\n",
        "Este ejemplo consiste en armar BOT simple basado en una red neuronal con Tensorflow\n",
        "\n",
        "**Author:** Hernán Contigiani<br>\n",
        "[Github](https://github.com/hernancontigiani/)<br>\n",
        "[Linkedin](https://www.linkedin.com/in/hern%C3%A1n-contigiani-41260679/?locale=en_US)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXwyiPUBdA3i",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import string\n",
        "import random \n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvETOouHynAu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "if os.access('lematizacion-es.pickle', os.F_OK) is False:\n",
        "    if os.access('lematizacion-es.zip', os.F_OK) is False:\n",
        "        url = 'https://drive.google.com/uc?id=16leuM9PuFXAkmw34XeQy-84h8WGAYxJw&export=download'\n",
        "        output = 'lematizacion-es.zip'\n",
        "        gdown.download(url, output, quiet=False)\n",
        "    !unzip -q lematizacion-es.zip\n",
        "else:\n",
        "    print(\"El archivo ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1BGCceizG5b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "with open(\"lematizacion-es.pickle\",'rb') as fi:\n",
        "    lemma_lookupTable = pickle.load(fi)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AZJ-9ME-zz9C"
      },
      "source": [
        "# Recolectar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1D8L5lA4zmMT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Dataset en formato JSON que representa las posibles preguntas (patterns)\n",
        "# y las posibles respuestas por categoría (tag)\n",
        "data = {\"intents\": [\n",
        "             {\"tag\": \"bienvenida\",\n",
        "              \"patterns\": [\"Hola\", \"¿Cómo estás?\", \"¿Qué tal?\"],\n",
        "              \"responses\": [\"Hola!\", \"Hola, ¿Cómo estás?\"],\n",
        "             },\n",
        "             {\"tag\": \"nombre\",\n",
        "              \"patterns\": [\"¿Cúal es tu nombre?\", \"¿Quién sos?\"],\n",
        "              \"responses\": [\"Mi nombre es MarvelBOT\", \"Yo soy MarvelBOT\"]\n",
        "             },\n",
        "            {\"tag\": \"contacto\",\n",
        "              \"patterns\": [\"contacto\", \"número de contacto\", \"número de teléfono\", \"número de whatsapp\", \"whatsapp\"],\n",
        "              \"responses\": [\"Podes contactarnos al siguiente número +54-9-11-2154-4777\", \"Contactonos al whatsapp número +54-9-11-2154-4777\"]\n",
        "             },\n",
        "            {\"tag\": \"envios\",\n",
        "              \"patterns\": [\"¿Realizan envios?\", \"¿Cómo me llega el paquete?\"],\n",
        "              \"responses\": [\"Los envios se realizan por correo, lo enviaremos a la dirección que registraste en la página\"]\n",
        "             },\n",
        "            {\"tag\": \"precios\",\n",
        "              \"patterns\": [\"precio\", \"Me podrás pasar los precios\", \"¿Cuánto vale?\", \"¿Cuánto sale?\"],\n",
        "              \"responses\": [\"En el catálogo podrás encontrar los precios de todos nuestros productos en stock\"]\n",
        "             },\n",
        "            {\"tag\": \"pagos\",\n",
        "              \"patterns\": [\"medios de pago\", \"tarjeta de crédito\", \"tarjetas\", \"cuotas\"],\n",
        "              \"responses\": [\"Contactanos al whatsapp número +54-9-11-2154-4777 para conocer los beneficios y formas de pago vigentes\"]\n",
        "             },\n",
        "            {\"tag\": \"stock\",\n",
        "              \"patterns\": [\"Esto está disponible\", \"¿Tenes stock?\", \"¿Hay stock?\"],\n",
        "              \"responses\": [\"Los productos publicados están en stock\"]\n",
        "             },\n",
        "            {\"tag\": \"agradecimientos\",\n",
        "              \"patterns\": [ \"Muchas gracias\", \"Gracias\"],\n",
        "              \"responses\": [\"Por nada!, cualquier otra consulta podes escribirnos\"]\n",
        "             },\n",
        "             {\"tag\": \"despedida\",\n",
        "              \"patterns\": [ \"Chau\", \"Hasta luego!\"],\n",
        "              \"responses\": [\"Hasta luego!\", \"Hablamos luego!\"]\n",
        "             }\n",
        "]}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PM2E2ylVz9HK"
      },
      "source": [
        "# Procesar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d7kWJClU0Zs_"
      },
      "source": [
        "### Herramientas de preprocesamiento de datos\n",
        "Entre las tareas de procesamiento de texto en español se implementa:\n",
        "- Quitar números\n",
        "- Quitar símbolos de puntuación\n",
        "- Quitar caracteres acentuados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEPO44To0XDE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "# El preprocesamento en castellano requiere más trabajo\n",
        "\n",
        "def preprocess_clean_text(text):\n",
        "    # pasar a minúsculas\n",
        "    text = text.lower()\n",
        "    # quitar números\n",
        "    pattern = r'[0-9\\n]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    # quitar caracteres de puntiación\n",
        "    text = ''.join([c for c in text if c not in (string.punctuation+\"¡\"+\"¿\")])\n",
        "    # quitar caracteres con acento\n",
        "    text = re.sub(r'[àáâä]', \"a\", text)\n",
        "    text = re.sub(r'[éèêë]', \"e\", text)\n",
        "    text = re.sub(r'[íìîï]', \"i\", text)\n",
        "    text = re.sub(r'[òóôö]', \"o\", text)\n",
        "    text = re.sub(r'[úùûü]', \"u\", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZsr8Em107nE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "string.punctuation + \"¡\" + \"¿\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJV1-EYR1BYk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "preprocess_clean_text(\"¿cómo5!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9HsCV870EDV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "words = []\n",
        "classes = []\n",
        "doc_X = []\n",
        "doc_y = []\n",
        "# Tokenizar cada \"pattern\" y agregar cada palabra al vocabulario (vocabulary)\n",
        "# Los tokens que se toman de cada pattern se agrega a doc_X\n",
        "# Cada tag se agrega a doc_y\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        # trasformar el patron a tokens\n",
        "        tokens = preprocess_clean_text(pattern).split(\" \")\n",
        "        # lematizar los tokens\n",
        "        lemma_words = []\n",
        "        for token in tokens:\n",
        "            lemma = lemma_lookupTable.get(token)\n",
        "            if lemma is not None:\n",
        "                lemma_words.append(lemma)\n",
        "            else:\n",
        "                print(\"UNK:\", token)\n",
        "        \n",
        "        if not lemma_words:\n",
        "            continue\n",
        "        \n",
        "        words += lemma_words\n",
        "        doc_X.append(pattern)\n",
        "        doc_y.append(intent[\"tag\"])\n",
        "    \n",
        "    # Agregar el tag a las clases\n",
        "    if intent[\"tag\"] not in classes:\n",
        "        classes.append(intent[\"tag\"])\n",
        "\n",
        "# Elminar duplicados con \"set\" y ordenar el vocubulario y las clases por orden alfabético\n",
        "vocab = sorted(set(words))\n",
        "classes = sorted(set(classes))\n",
        "len(vocab)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VMQcLbEM3fTZ"
      },
      "source": [
        "# Explorar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUweP3bG3hUT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(\"vocab:\", vocab)\n",
        "print(\"classes:\", classes)\n",
        "print(\"doc_X:\", doc_X)\n",
        "print(\"doc_y:\", doc_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po1JduvCpezn",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "doc_y_encoded = [classes.index(label) for label in doc_y]\n",
        "doc_y_encoded"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_PUzAtcW3zsO"
      },
      "source": [
        "# Entrenar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_zR85n9sE3k",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "X_train = np.array(doc_X).reshape(-1, 1)\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p4h82Q9sQ2I",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6gfIh3Vou_h",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "y_train = tf.keras.utils.to_categorical(doc_y_encoded)\n",
        "y_train[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtyHpTUarCVK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "output_shape = y_train.shape[1]\n",
        "output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31S4N1PM353A",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class CustomTextVectorization(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_data, lookupTable):\n",
        "        super().__init__()\n",
        "        keys, values = list(zip(*lookupTable.items()))\n",
        "        table_init = tf.lookup.KeyValueTensorInitializer(keys, values)\n",
        "        self.table = tf.lookup.StaticHashTable(table_init, \"UNK\")\n",
        "        self.vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "            output_mode = \"binary\",\n",
        "            split = self.custom_split,\n",
        "            standardize=self.custom_lemmatization,\n",
        "            max_tokens=len(vocab_data)+1, # vocab + UNK\n",
        "            vocabulary=vocab_data\n",
        "        )\n",
        "        self.punctuation = string.punctuation + \"¡\" + \"¿\"\n",
        "\n",
        "    def custom_lemmatization(self, input_string):\n",
        "        # pasar a minúsculas\n",
        "        output_string = tf.strings.lower(input_string, encoding='utf-8')\n",
        "        # quitar números\n",
        "        pattern = r'[0-9\\n]' \n",
        "        output_string = tf.strings.regex_replace(output_string, pattern, '')\n",
        "        # quitar signos de puntuacion\n",
        "        output_string = tf.strings.regex_replace(\n",
        "            output_string, \"[%s]\" % re.escape(self.punctuation), '')\n",
        "        # quitar caracteres con acento\n",
        "        output_string = tf.strings.regex_replace(output_string, r'[àáâä]', 'a')\n",
        "        output_string = tf.strings.regex_replace(output_string, r'[éèêë]', 'e')\n",
        "        output_string = tf.strings.regex_replace(output_string, r'[íìîï]', 'i')\n",
        "        output_string = tf.strings.regex_replace(output_string, r'[òóôö]', 'o')\n",
        "        output_string = tf.strings.regex_replace(output_string, r'[úùûü]', 'u')\n",
        "        return output_string\n",
        "\n",
        "    def custom_split(self, input_string):\n",
        "        # split por espacios\n",
        "        strings = tf.strings.split(input_string, sep=\" \")\n",
        "        # a cada token se lo lematiza\n",
        "        strings = self.table.lookup(strings)\n",
        "        return strings\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.vectorize_layer(inputs)\n",
        "\n",
        "custom_textVectorization = CustomTextVectorization(vocab, lemma_lookupTable)\n",
        "custom_textVectorization.trainable = False\n",
        "custom_textVectorization([\"hola cómo!\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5934QwbrnVl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model_preprocess = Sequential()\n",
        "model_preprocess.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "model_preprocess.add(custom_textVectorization)\n",
        "model_preprocess.build()\n",
        "model_preprocess.summary()\n",
        "model_preprocess.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-p3xgnPrJpY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del modelo DNN\n",
        "# - Modelo secuencial\n",
        "# - Con regularización\n",
        "# - softmax y optimizador Adam\n",
        "model = Sequential()\n",
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "model.add(custom_textVectorization)\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(output_shape, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGpqs-HGrelu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "hist = model.fit(x=X_train, y=y_train, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlWHk0mxt9dB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X8Mt0k2auCYn"
      },
      "source": [
        "# Utilizar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtkB3SyV55_w",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "responses = [[\"\"]] * len(classes)\n",
        "max_possible_responses = 0\n",
        "for intent in data[\"intents\"]:\n",
        "    max_possible_responses = max(max_possible_responses, len(intent[\"responses\"]))\n",
        "    responses[classes.index(intent[\"tag\"])] = intent[\"responses\"]\n",
        "\n",
        "# Para poder trabajar con las respuestas es necesario pasarlo a formato\n",
        "# de matriz. Para eso, cada fila (tag) debe tener la misma cantidad de posibles\n",
        "# respuestas\n",
        "# Con el código a continuación se ajustan las respuestas y se repiten aquellas\n",
        "# en donde la cantidad es menor a la requerida para formar una matriz\n",
        "for i in range(len(responses)):\n",
        "    if len(responses[i]) < max_possible_responses:\n",
        "        responses[i] = list(np.resize(responses[i], max_possible_responses))\n",
        "\n",
        "responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SGei5U6zsES",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class CustomOutput(tf.keras.layers.Layer):\n",
        "    def __init__(self, responses, threshold=0.2):\n",
        "        super().__init__()\n",
        "        self.responses = tf.constant(responses)\n",
        "        self.maxval = self.responses.shape[1]\n",
        "        self.default_output = tf.constant(\"Perdon, no pude entenderte\")\n",
        "        self.threshold =tf.constant(threshold)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        score = tf.math.reduce_max(inputs)  # equivale a max()\n",
        "        index = tf.math.argmax(inputs, axis=1)[0]  # equivale a argmax\n",
        "        responses = tf.gather(self.responses, index)  # equivale a self.responses[index]\n",
        "        \n",
        "        # equivale a responses[random.randrange(0, maxval)]\n",
        "        label = responses[tf.random.uniform(shape=(), minval=0, maxval=self.maxval, dtype=tf.int32)]\n",
        "\n",
        "        # equivale a--> return label if score > 0.4 else \"Perdón, no pude entenderte\"\n",
        "        output = tf.cond(score > self.threshold, lambda: label, lambda: self.default_output)\n",
        "\n",
        "        # equivalente a reshape(1, -1) para retornar un vector (un array con texto dentro)\n",
        "        output = tf.expand_dims(output, 0)\n",
        "        return output\n",
        "\n",
        "postprocess = CustomOutput(responses, 0.4)\n",
        "postprocess(model.predict([\"hola!\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KexBK4TH1Ech",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "complete_model = Sequential()\n",
        "complete_model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "complete_model.add(model)\n",
        "complete_model.add(postprocess)\n",
        "complete_model.build()\n",
        "complete_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zoD3mgg0gXC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "complete_model.predict([\"Hola gente\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_AYOCkKukJL",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "MODEL_DIR = \"chatbot\"\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "tf.keras.models.save_model(\n",
        "    complete_model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VkfsWDHvrRa",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!zip -r chatbot.zip chatbot"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3- chatbot_dnn_tfx.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
